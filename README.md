# NeuroToken
Capturing Author Style with LSTM and Soundex Tokens.

This project aims to provide another perspective to the problem of embedding author style into the machine learning process - to create
a model that can be used to generate text in the stylistic of the author of the original texts being learned. The project objectives are:

- Capture the author "style" and generate text in similar stylistic.
- Use vocabulary from another source to mimic original author style, e.g. Trump writing Shakespearean sonnets.

This will be achieved by:
- Developing a new approach, encoding words from Text 1 by their morphological structure and representing words as tokens.
- Feeding above tokens into Long short-term memory Recurrent Neural Network (LSTM - RNN) for learning.
- Decoding tokens generated by model to keep original author style, but using another author vocabulary from Text 2.

---

1. Import datasets/texts as plain text - Text 1 will be used to learn the author style, Text 2 will be used as vocabulary/dictionary source
for converting LSTM result back into human-readable text.
2. Clean and normalise Text 1 - remove redundant white space, punctuation, non-English words; convert to lower case. This can greatly enhance training times.
3. Clean and normalise Text 2. Split sentences into individual words.
4. Parse Text 1, generating different style corpuses (see code).
5. Parse Text 2, generating key-value vocabulary pairs.
6. Feed the Text 1 style corpus into LSTM-128 / Bidirectional LSTM-128.
7. Generate characters from model, e.g. 2000 characters. Split by white space.
8. Use Levenshtein Distance to and closest match for encoding from generated result in Text 2 - effective for situation if token for word in Text 1 is not present in Text 2. Optionally, impose additional
constraints, e.g. syllable count, rhythm, rhyme.
9. Retrieve plain text word associated with encoding token and format as required.

<a href="https://ibb.co/XkSnKkb"><img src="https://i.ibb.co/prJHMrx/Neuro-Token.png" alt="Neuro-Token" border="0"></a>
